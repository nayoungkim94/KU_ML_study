{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0|    2.4520|     0.376| 45.660004\n",
      "   10|    1.1036|  0.003398|  0.206336\n",
      "   20|    1.0128|  -0.02091|  0.001026\n",
      "   30|    1.0065|  -0.02184|  0.000093\n",
      "   40|    1.0059|  -0.02123|  0.000083\n",
      "   50|    1.0057|  -0.02053|  0.000077\n",
      "   60|    1.0055|  -0.01984|  0.000072\n",
      "   70|    1.0053|  -0.01918|  0.000067\n",
      "   80|    1.0051|  -0.01854|  0.000063\n",
      "   90|    1.0050|  -0.01793|  0.000059\n",
      "  100|    1.0048|  -0.01733|  0.000055\n"
     ]
    }
   ],
   "source": [
    "#Lab02_SimpleLinearRegression\n",
    "\n",
    "#data\n",
    "x_data = [1,2,3,4,5]\n",
    "y_data = [1,2,3,4,5]\n",
    "W = tfe.Variable(2.9)\n",
    "b = tfe.Variable(0.5)\n",
    "learning_rate = 0.01\n",
    "for i in range(100+1):\n",
    "    # Gradient descent\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis=W*x_data+b\n",
    "        cost=tf.reduce_mean(tf.square(hypothesis-y_data))\n",
    "    W_grad, b_grad=tape.gradient(cost, [W,b])\n",
    "    W.assign_sub(learning_rate*W_grad)\n",
    "    b.assign_sub(learning_rate*b_grad)\n",
    "    if i %10==0:\n",
    "        print(\"{:5}|{:10.4f}|{:10.4}|{:10.6f}\".format(i, W.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.00667, shape=(), dtype=float32)\n",
      "tf.Tensor(2.4946702, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(W*5+b)\n",
    "print(W*2.5+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "#Lab03_How to minimize cost\n",
    "\n",
    "#cost function in pure Python\n",
    "import numpy as np\n",
    "X=np.array([1,2,3])\n",
    "Y=np.array([1,2,3])\n",
    "\n",
    "def cost_func(W,X,Y):\n",
    "    c=0\n",
    "    for i in range(len(X)):\n",
    "        c+=(W*X[i]-Y[i])**2\n",
    "    return c/len(X)\n",
    "\n",
    "for feed_W in np.linspace(-3,5,num=15):\n",
    "    curr_cost = cost_func(feed_W,X,Y)\n",
    "    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.000 |   74.66667\n",
      "-2.429 |   54.85714\n",
      "-1.857 |   38.09524\n",
      "-1.286 |   24.38095\n",
      "-0.714 |   13.71429\n",
      "-0.143 |    6.09524\n",
      " 0.429 |    1.52381\n",
      " 1.000 |    0.00000\n",
      " 1.571 |    1.52381\n",
      " 2.143 |    6.09524\n",
      " 2.714 |   13.71429\n",
      " 3.286 |   24.38095\n",
      " 3.857 |   38.09524\n",
      " 4.429 |   54.85714\n",
      " 5.000 |   74.66667\n"
     ]
    }
   ],
   "source": [
    "#cost function in tensorflow\n",
    "def cost_func_tensor(W,X,Y): \n",
    "    hypothesis=X*W\n",
    "    return tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "W_values=np.linspace(-3,5,num=15)\n",
    "cost_values=[]\n",
    "\n",
    "for feed_W in W_values:\n",
    "    curr_cost=cost_func_tensor(feed_W,X,Y)\n",
    "    cost_values.append(curr_cost)\n",
    "    print(\"{:6.3f} | {:10.5f}\".format(feed_W, curr_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 11716.3086 |  48.767971\n",
      "   10 |  4504.9126 |  30.619968\n",
      "   20 |  1732.1364 |  19.366755\n",
      "   30 |   666.0052 |  12.388859\n",
      "   40 |   256.0785 |   8.062004\n",
      "   50 |    98.4620 |   5.379007\n",
      "   60 |    37.8586 |   3.715335\n",
      "   70 |    14.5566 |   2.683725\n",
      "   80 |     5.5970 |   2.044044\n",
      "   90 |     2.1520 |   1.647391\n",
      "  100 |     0.8275 |   1.401434\n",
      "  110 |     0.3182 |   1.248922\n",
      "  120 |     0.1223 |   1.154351\n",
      "  130 |     0.0470 |   1.095710\n",
      "  140 |     0.0181 |   1.059348\n",
      "  150 |     0.0070 |   1.036801\n",
      "  160 |     0.0027 |   1.022819\n",
      "  170 |     0.0010 |   1.014150\n",
      "  180 |     0.0004 |   1.008774\n",
      "  190 |     0.0002 |   1.005441\n",
      "  200 |     0.0001 |   1.003374\n",
      "  210 |     0.0000 |   1.002092\n",
      "  220 |     0.0000 |   1.001297\n",
      "  230 |     0.0000 |   1.000804\n",
      "  240 |     0.0000 |   1.000499\n",
      "  250 |     0.0000 |   1.000309\n",
      "  260 |     0.0000 |   1.000192\n",
      "  270 |     0.0000 |   1.000119\n",
      "  280 |     0.0000 |   1.000074\n",
      "  290 |     0.0000 |   1.000046\n"
     ]
    }
   ],
   "source": [
    "#Gradient descent in tensorflow\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "x_data = [1.,2.,3.,4.]\n",
    "y_data = [1.,3.,5.,7.]\n",
    "W=tfe.Variable(tf.random_normal([1],-100.,100.))\n",
    "for step in range(300):\n",
    "    hypothesis=W*X\n",
    "    cost= tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "    alpha=0.01\n",
    "    gradient=tf.reduce_mean((hypothesis-Y)*X)     #gradient=tf.reduce_mean(tf.multiply((hypothesis-Y),X))\n",
    "    \n",
    "    descent=W-tf.multiply(alpha, gradient) #why they use multiply? not * ?\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10==0:\n",
    "        print(\"{:5} | {:10.4f} | {:10.6f}\".format(step, cost.numpy(),W.numpy()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   168.0000 |   6.720000\n",
      "   10 |    64.5959 |   4.546858\n",
      "   20 |    24.8371 |   3.199336\n",
      "   30 |     9.5498 |   2.363764\n",
      "   40 |     3.6719 |   1.845643\n",
      "   50 |     1.4118 |   1.524366\n",
      "   60 |     0.5429 |   1.325149\n",
      "   70 |     0.2087 |   1.201618\n",
      "   80 |     0.0803 |   1.125020\n",
      "   90 |     0.0309 |   1.077522\n",
      "  100 |     0.0119 |   1.048070\n",
      "  110 |     0.0046 |   1.029807\n",
      "  120 |     0.0018 |   1.018483\n",
      "  130 |     0.0007 |   1.011461\n",
      "  140 |     0.0003 |   1.007107\n",
      "  150 |     0.0001 |   1.004407\n",
      "  160 |     0.0000 |   1.002732\n",
      "  170 |     0.0000 |   1.001694\n",
      "  180 |     0.0000 |   1.001051\n",
      "  190 |     0.0000 |   1.000651\n",
      "  200 |     0.0000 |   1.000404\n",
      "  210 |     0.0000 |   1.000250\n",
      "  220 |     0.0000 |   1.000155\n",
      "  230 |     0.0000 |   1.000096\n",
      "  240 |     0.0000 |   1.000060\n",
      "  250 |     0.0000 |   1.000037\n",
      "  260 |     0.0000 |   1.000023\n",
      "  270 |     0.0000 |   1.000014\n",
      "  280 |     0.0000 |   1.000009\n",
      "  290 |     0.0000 |   1.000006\n"
     ]
    }
   ],
   "source": [
    "x_data = [1.,2.,3.,4.]\n",
    "y_data = [1.,3.,5.,7.]\n",
    "W=tf.Variable([7.0])\n",
    "for step in range(300):\n",
    "    hypothesis=W*X\n",
    "    cost= tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "    alpha=0.01\n",
    "    gradient=tf.reduce_mean((hypothesis-Y)*X)     #gradient=tf.reduce_mean(tf.multiply((hypothesis-Y),X))\n",
    "    \n",
    "    descent=W-tf.multiply(alpha, gradient) #why they use multiply? not * ?\n",
    "    W.assign(descent)\n",
    "    \n",
    "    if step % 10==0:\n",
    "        print(\"{:5} | {:10.4f} | {:10.6f}\".format(step, cost.numpy(),W.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 |   16795.3691\n",
      "   50 |     295.4906\n",
      "  100 |     112.1119\n",
      "  150 |     109.7831\n",
      "  200 |     109.4639\n",
      "  250 |     109.1681\n",
      "  300 |     108.8729\n",
      "  350 |     108.5789\n",
      "  400 |     108.2854\n",
      "  450 |     107.9931\n",
      "  500 |     107.7014\n",
      "  550 |     107.4103\n",
      "  600 |     107.1203\n",
      "  650 |     106.8311\n",
      "  700 |     106.5426\n",
      "  750 |     106.2548\n",
      "  800 |     105.9679\n",
      "  850 |     105.6816\n",
      "  900 |     105.3963\n",
      "  950 |     105.1116\n",
      " 1000 |     104.8274\n"
     ]
    }
   ],
   "source": [
    "#Lab04_Mulitvariable linear regression\n",
    "\n",
    "x1 = [73., 93., 89., 96., 73.]\n",
    "x2 = [80., 88., 91., 98., 66.]\n",
    "x3 = [75., 93., 90., 100.,70.]\n",
    "Y=[152.,185., 180.,196., 142.]\n",
    "\n",
    "# initial value of W,b\n",
    "w1=tf.Variable(tf.random_normal([1]))\n",
    "w2=tf.Variable(tf.random_normal([1]))\n",
    "w3=tf.Variable(tf.random_normal([1]))\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "learning_rate=0.000001\n",
    "\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis=w1*x1+w2*x2+w3*x3+b\n",
    "        cost=tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "    w1_grad, w2_grad, w3_grad, b_grad=tape.gradient(cost, [w1,w2,w3,b])\n",
    "    \n",
    "    #updating w1,w2,w3,b\n",
    "    w1.assign_sub(learning_rate*w1_grad)\n",
    "    w2.assign_sub(learning_rate*w2_grad)\n",
    "    w3.assign_sub(learning_rate*w3_grad)\n",
    "    b.assign_sub(learning_rate*b_grad)\n",
    "    if i %50==0:\n",
    "        print (\"{:5} | {:12.4f}\".format(i,cost.numpy()))\n",
    "        # print(\"{:5}|{:10.4f}|{:10.4}|{:10.6f}|{:10.6f}|{:10.6f}\".format(i, w1.numpy(),w2.numpy(),w3.numpy(), b.numpy(), cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0 | 195206.6562\n",
      "  100 |    40.8115\n",
      "  200 |    16.6931\n",
      "  300 |    16.6015\n",
      "  400 |    16.5132\n",
      "  500 |    16.4254\n",
      "  600 |    16.3381\n",
      "  700 |    16.2514\n",
      "  800 |    16.1649\n",
      "  900 |    16.0791\n",
      " 1000 |    15.9937\n",
      " 1100 |    15.9088\n",
      " 1200 |    15.8243\n",
      " 1300 |    15.7403\n",
      " 1400 |    15.6566\n",
      " 1500 |    15.5736\n",
      " 1600 |    15.4908\n",
      " 1700 |    15.4087\n",
      " 1800 |    15.3268\n",
      " 1900 |    15.2455\n",
      " 2000 |    15.1645\n"
     ]
    }
   ],
   "source": [
    "# by Matrix\n",
    "data=np.array([\n",
    "    # X1, X2, X3, Y\n",
    "    [73. ,80. , 75. ,152.],\n",
    "    [93. , 88. ,93. ,185.],\n",
    "    [89. ,91. , 90. ,180.],\n",
    "    [96. , 98. ,100. ,196.],\n",
    "    [73. , 66. ,70. , 142.]\n",
    "], dtype=np.float32)\n",
    "\n",
    "#slicing data\n",
    "X=data[:,:-1]\n",
    "y=data[:,[-1]]\n",
    "\n",
    "# initial value of W,b\n",
    "W=tf.Variable(tf.random_normal([3,1])) # W: row=3, col=1\n",
    "b=tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "learning_rate=0.000001\n",
    "\n",
    "#prediction function, hypothesis\n",
    "def predict(X):\n",
    "    return tf.matmul(X,W)+b #matrix multiply\n",
    "\n",
    "n_epochs=2000\n",
    "for i in range(n_epochs+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost=tf.reduce_mean(tf.square(predict(X)-y))\n",
    "    # updating W,b\n",
    "    W_grad, b_grad=tape.gradient(cost, [W,b])\n",
    "    W.assign_sub(learning_rate*W_grad)\n",
    "    b.assign_sub(learning_rate*b_grad)\n",
    "    if i %100==0:\n",
    "        print (\"{:5} | {:10.4f}\".format(i,cost.numpy()))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
