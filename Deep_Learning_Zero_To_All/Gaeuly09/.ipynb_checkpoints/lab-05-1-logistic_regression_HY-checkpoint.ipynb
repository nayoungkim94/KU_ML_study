{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모두를 위한 딥러닝 시즌 2 Lab 05\n",
    "\n",
    "모두를 위한 딥러닝 시즌 2의 github code 자료를 바탕으로 작성되었습니다. \n",
    "\n",
    "이 코드는 tensorflow 2.0.0-beta1에서 작성되었습니다. \n",
    " \n",
    "+ Logistic regression (Classfication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "* x_data가 2차원 배열(2개의 설명변수)이기에 2차원 공간에 표현\n",
    "* x1과 x2를 이용하여 y_data을 0과 1로 구분하는 예제\n",
    "* 그림에서 보면 Logistic Classification 통해 보라색과 노란색 y_data(Label)을 구분하는 것과 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x183673fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = [[1., 2.],\n",
    "          [2., 3.],\n",
    "          [3., 1.],\n",
    "          [4., 3.],\n",
    "          [5., 3.],\n",
    "          [6., 2.]]\n",
    "y_train = [[0.],\n",
    "          [0.],\n",
    "          [0.],\n",
    "          [1.],\n",
    "          [1.],\n",
    "          [1.]]\n",
    "\n",
    "x_test = [[5.,2.]]\n",
    "y_test = [[1.]]\n",
    "\n",
    "\n",
    "x1 = [x[0] for x in x_train]\n",
    "x2 = [x[1] for x in x_train]\n",
    "\n",
    "colors = [int(y[0] % 3) for y in y_train]\n",
    "plt.scatter(x1,x2, c=colors , marker='^')\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tensorflow Eager\n",
    "### Train Data를 기준으로 Logistic Classification 모델 적합\n",
    "* Tensorflow data API를 통해 학습시킬 값들을 dataset에 저장 (Batch Size = 한번에 학습시킬 Size)\n",
    "* 실제 학습에 쓰일 Data(features,labels)는 연산을 위해 Type를 맞춤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* W와 b은 학습을 통해 생성되는 모델의 Wegith와 Bias\n",
    "* W와 b의 초기값을 아래와 같이 0으로 하거나 Random값으로 가능 (tf.random_normal([2, 1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid 함수를 가설로 선언\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.math.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(features):\n",
    "    hypothesis  = tf.div(1., 1. + tf.exp(tf.matmul(features, W) + b))\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설을 검증할 Cost 함수를 정의합니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if  &  y=0\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위 두 식을 합치면 아래과 같다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(hypothesis, features, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "optimizer = tf.optimizers.SGD(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.5를 기준으로 추론한 값을 0과 1의 값으로 변환\n",
    "* Sigmoid 함수를 통해 예측값이 0.5보다 크면 1을 반환하고 0.5보다 작으면 0으로 반환합니다.\n",
    "* 실제 데이터에서의 0,1의 비율에 따라 0.5가 아닌 다른 cut-off를 사용할 수 있다. \n",
    "* 이를 이용해 실제 값과 예측한 값을 비교한 정확도를 측정합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientTape를 통해 경사값을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(hypothesis, features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_fn(logistic_regression(features),features,labels)\n",
    "    return tape.gradient(loss_value, [W,b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 반복적 학습을 실행\n",
    "* 위의 Data를 Cost함수를 통해 학습시킨 후 모델을 생성합니다. \n",
    "* 새로운 Data를 통한 검증 수행 [5,2]의 Data로 테스트 수행 (그래프상 1이 나와야 정상입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'div'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-406eb5985b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-6afa75b867be>\u001b[0m in \u001b[0;36mlogistic_regression\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhypothesis\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'div'"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1001\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "    for features, labels  in dataset:\n",
    "        grads = grad(logistic_regression(features), features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),features,labels)))\n",
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
